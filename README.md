<div align="center">

# ğŸ™ï¸ Offline Hindi Voice Assistant

### Privacy-First Â· Fully Offline Â· Hindi-First Â· ARM-Ready

[![Platform](https://img.shields.io/badge/Platform-Windows%20PC%20%7C%20Raspberry%20Pi-blue?style=flat-square)](.)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=flat-square&logo=python&logoColor=white)](.)
[![ASR](https://img.shields.io/badge/ASR-IndicWav2Vec2%20ONNX-orange?style=flat-square)](.)
[![TTS](https://img.shields.io/badge/TTS-Piper%20hi__IN--pratham-green?style=flat-square)](.)
[![License](https://img.shields.io/badge/License-MIT-lightgrey?style=flat-square)](LICENSE)
[![Status](https://img.shields.io/badge/Windows%20Deployed-%E2%9C%93%20Live-success?style=flat-square)](.)

<br/>

> A low-latency, privacy-preserving voice assistant that understands and responds in **Hindi** â€”  
> fully developed and deployed on **Windows OS (Terminal)**, and architecturally ready for **Raspberry Pi / ARM SBC**.

</div>

---

## ğŸ“Œ Deployment Status

| Environment | Status | Notes |
|---|---|---|
| ğŸ–¥ï¸ **Windows PC (Terminal)** | âœ… **Fully Deployed & Tested** | All pipeline stages validated end-to-end |
| ğŸ“ **Raspberry Pi 4 / ARM SBC** | ğŸ”œ **Architecture Complete** | ARM binaries included â€” pending physical hardware |
| ğŸ–¥ï¸ **QEMU ARM Emulation** | âœ… **Validated** | Pipeline tested via QEMU aarch64 chroot |

> **Note:** This project was entirely developed, integrated, and tested on a **Windows OS terminal environment**. The codebase is cross-platform by design â€” all ARM binaries, shared libraries, and deployment scripts are included and validated. Physical Raspberry Pi deployment was not completed due to hardware availability constraints at the time of submission.

---

## ğŸ—ï¸ System Architecture

The assistant runs an **8-stage, fully offline speech pipeline**. Every stage is a self-contained module:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  HINDI VOICE ASSISTANT PIPELINE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  [Microphone]
        â”‚   512-sample PCM frames @ 16 kHz
        â–¼
  [VADListener]          Silero VAD (PyTorch)  â€”  speech_prob > 0.6
        â”‚   Accumulated speech segment (numpy float32)
        â–¼
  [AudioProcessor]       Max-normalise  â†’  expand_dims  â†’  shape (1, N)
        â”‚
        â–¼
  [ASRInference]         IndicWav2Vec2 ONNX  â€”  CTC greedy decode
        â”‚   Hindi transcript string (Devanagari)
        â–¼
  [WakeController]       "à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€"  â€”  activate / execute mode
        â”‚   Cleaned command text
        â–¼
  [HybridIntentEngine]   Rule Engine  â†’  IndicBERT fallback
        â”‚   Intent label string
        â–¼
  [TaskEngine]           Dispatch  â†’  Scheduler / Medical / System
        â”‚   Hindi response string
        â–¼
  [PiperTTS]             hi_IN-pratham-medium.onnx  â€”  subprocess
        â”‚
        â–¼
  [Audio Playback]       soundfile  +  sounddevice
```

---

## âœ¨ Key Features

| Feature | Detail |
|---|---|
| ğŸŒ **Fully Offline** | Zero network calls at runtime â€” no cloud, no API keys |
| ğŸ”’ **Privacy Preserving** | Audio never stored; no external data transmission |
| ğŸ—£ï¸ **Hindi ASR** | IndicWav2Vec2 exported to ONNX, CTC greedy decoder |
| ğŸ”Š **Hindi TTS** | Piper `hi_IN-pratham-medium` â€” natural offline Hindi voice |
| ğŸ¯ **Hybrid NLU** | Rule engine (25+ intents) + IndicBERT semantic fallback |
| âš¡ **Low Latency** | ~300â€“400 ms on PC Â· ~700â€“1050 ms projected on RPi 4 |
| ğŸ–¥ï¸ **Cross-Platform** | Windows `piper.exe` + ARM Linux `piper` â€” auto-detected at runtime |
| ğŸ™ï¸ **Wakeword** | `à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€` â€” two-step and inline activation modes |

---

## ğŸ“ Project Structure

```
HindiVoiceAssistant/
â”‚
â”œâ”€â”€ main.py                              â† Master pipeline entry point
â”œâ”€â”€ requirements.txt                     â† Windows PC dependencies
â”œâ”€â”€ requirements_arm.txt                 â† Raspberry Pi / ARM dependencies
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ bin/
â”‚   â””â”€â”€ piper/
â”‚       â”œâ”€â”€ windows/                     â† piper.exe + libonnxruntime.dll + libespeak-ng.dll
â”‚       â””â”€â”€ arm/                         â† piper (ELF) + .so libs + espeak-ng-data/
â”‚           â””â”€â”€ espeak-ng-data/          â† hi_dict, phondata, phonindex, phontab
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ asr/
â”‚   â”‚   â””â”€â”€ indicwav2vec2_hindi/         â† vocab.json + config.json + tokenizer files
â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â””â”€â”€ piper/                       â† hi_IN-pratham-medium.onnx + .onnx.json
â”‚   â””â”€â”€ vad/                             â† Silero VAD (auto-cached via torch.hub)
â”‚
â”œâ”€â”€ onnx_models/
â”‚   â””â”€â”€ asr/
â”‚       â”œâ”€â”€ indicwav2vec2_hindi.onnx     â† Exported ONNX graph
â”‚       â””â”€â”€ indicwav2vec2_hindi.onnx.dataâ† External weights (>2 GB split)
â”‚
â”œâ”€â”€ runtime/                             â† All pipeline source modules
â”‚   â”œâ”€â”€ asr/
â”‚   â”‚   â””â”€â”€ asr_onnx_infer.py            â† ONNX inference + CTC decode
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â””â”€â”€ mic_recorder.py              â† 512-sample mic capture
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ wake_controller.py           â† Wakeword detection logic
â”‚   â”œâ”€â”€ nlu/
â”‚   â”‚   â”œâ”€â”€ hybrid_intent.py             â† Rule + BERT orchestrator
â”‚   â”‚   â”œâ”€â”€ rule_intent.py               â† 25+ Devanagari keyword rules
â”‚   â”‚   â””â”€â”€ indicbert_infer.py           â† IndicBERT fallback (placeholder)
â”‚   â”œâ”€â”€ processor/
â”‚   â”‚   â””â”€â”€ audio_processor.py           â† Normalise + tensor prep
â”‚   â”œâ”€â”€ task/
â”‚   â”‚   â”œâ”€â”€ task_engine.py               â† Intent dispatcher
â”‚   â”‚   â”œâ”€â”€ scheduler.py                 â† JSON-backed reminder store
â”‚   â”‚   â”œâ”€â”€ medical_engine.py            â† Patient record manager
â”‚   â”‚   â””â”€â”€ data/                        â† reminders.json, patients.json
â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â””â”€â”€ piper_tts.py                 â† Piper subprocess TTS engine
â”‚   â””â”€â”€ vad/
â”‚       â””â”€â”€ vad_listener.py              â† Silero VAD stream listener
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_asr.py                      â† ASR inference unit test
â”‚   â”œâ”€â”€ test_nlu.py                      â† NLU intent matching test
â”‚   â”œâ”€â”€ test_task_engine.py              â† Task dispatch test
â”‚   â””â”€â”€ test_tts.py                      â† TTS synthesis test
â”‚
â””â”€â”€ tools/
    â””â”€â”€ cleanup_project.py               â† Remove __pycache__, .wav, .log files
```

---

## âš™ï¸ Installation

### ğŸ–¥ï¸ Windows PC â€” Deployed & Tested

**Prerequisites:** Python 3.11 Â· Windows 10/11 Â· Microphone

```cmd
:: Step 1 â€” Clone repository
git clone https://github.com/<your-username>/HindiVoiceAssistant.git
cd HindiVoiceAssistant

:: Step 2 â€” Install Python dependencies
pip install -r requirements.txt

:: Step 3 â€” Place model files (see Model Downloads section below)
::   onnx_models/asr/indicwav2vec2_hindi.onnx
::   onnx_models/asr/indicwav2vec2_hindi.onnx.data
::   models/asr/indicwav2vec2_hindi/vocab.json
::   models/tts/piper/hi_IN-pratham-medium.onnx

:: Step 4 â€” Run the assistant
python main.py
```

**Expected startup output:**
```
[VAD]  Loading Silero...       [VAD]  Ready.
[ASR]  Loading ONNX model...   [ASR]  Ready.
[NLU]  Rule engine ready.      [NLU]  IndicBERT fallback ready.
[Task] Engine ready.
[TTS]  Piper ready.
[System] Listening for: à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€
```

---

### ğŸ“ Raspberry Pi 4 â€” ARM Ready

**Prerequisites:** Raspberry Pi OS 64-bit (Bookworm) Â· Python 3.11 Â· USB Microphone

```bash
# Step 1 â€” System dependencies
sudo apt update && sudo apt install -y python3-pip libportaudio2 libsndfile1 git

# Step 2 â€” Clone repository
git clone https://github.com/<your-username>/HindiVoiceAssistant.git
cd HindiVoiceAssistant

# Step 3 â€” Python dependencies
pip3 install -r requirements_arm.txt
pip3 install torch --index-url https://download.pytorch.org/whl/cpu

# Step 4 â€” Set ARM binary permissions
chmod +x bin/piper/arm/piper
chmod +x bin/piper/arm/espeak-ng
chmod +x bin/piper/arm/piper_phonemize

# Step 5 â€” Run
python3 main.py

# Optional â€” Autostart on boot (add to /etc/rc.local before 'exit 0')
# su pi -c 'python3 /home/pi/HindiVoiceAssistant/main.py &'
```

---

## ğŸ—£ï¸ How to Use

### Step 1 â€” Start

```cmd
python main.py
```

### Step 2 â€” Activate with Wakeword

Speak clearly: **`à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€`**

### Step 3 â€” Give a Command

| Mode | Usage | Example |
|---|---|---|
| **Two-Step** | Say wakeword â†’ pause â†’ speak command | `à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€` â†’ [wait] â†’ `à¤¸à¤®à¤¯ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ` |
| **Inline** | Say wakeword + command together | `à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€ à¤¸à¤®à¤¯ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ` |
| **Timeout** | No command within 8 seconds | Assistant resets, listens again |

> **Tip:** The assistant also accepts the variant `à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¤à¥€` to handle natural ASR phoneme variation between à¤Ÿ and à¤¥.

---

## ğŸ“‹ Supported Commands

| Category | Say This (Hindi) | Intent | Expected Response |
|---|---|---|---|
| â° **Time** | `à¤¸à¤®à¤¯ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ` Â· `à¤•à¤¿à¤¤à¤¨à¤¾ à¤¬à¤œà¤¾` Â· `à¤Ÿà¤¾à¤‡à¤®` | `GET_TIME` | à¤…à¤­à¥€ 14:35 à¤¬à¤œà¥‡ à¤¹à¥ˆà¤‚ |
| ğŸ“… **Date** | `à¤¤à¤¾à¤°à¥€à¤–` Â· `à¤†à¤œ à¤•à¥Œà¤¨ à¤¸à¤¾ à¤¦à¤¿à¤¨` | `GET_DATE` | à¤†à¤œ 20 February 2025 à¤¹à¥ˆ |
| ğŸŒ¤ï¸ **Weather** | `à¤®à¥Œà¤¸à¤®` Â· `à¤¤à¤¾à¤ªà¤®à¤¾à¤¨` | `GET_WEATHER` | (offline response) |
| ğŸ’§ **Set Water Reminder** | `à¤ªà¤¾à¤¨à¥€ à¤¯à¤¾à¤¦` | `SET_WATER_REMINDER` | à¤ªà¤¾à¤¨à¥€ à¤ªà¥€à¤¨à¥‡ à¤•à¤¾ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥‡à¤Ÿ à¤¹à¥‹ à¤—à¤¯à¤¾ |
| ğŸ’§ **Remove Water** | `à¤ªà¤¾à¤¨à¥€ à¤¹à¤Ÿà¤¾à¤“` Â· `à¤ªà¤¾à¤¨à¥€ à¤¬à¤‚à¤¦` | `REMOVE_WATER_REMINDER` | à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¹à¤Ÿà¤¾ à¤¦à¤¿à¤¯à¤¾ |
| ğŸŒ¬ï¸ **Set Breath Reminder** | `à¤¸à¤¾à¤à¤¸ à¤¯à¤¾à¤¦` | `SET_BREATH_REMINDER` | à¤¸à¤¾à¤à¤¸ à¤•à¤¾ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥‡à¤Ÿ à¤¹à¥‹ à¤—à¤¯à¤¾ |
| ğŸŒ¬ï¸ **Remove Breath** | `à¤¸à¤¾à¤à¤¸ à¤¹à¤Ÿà¤¾à¤“` Â· `à¤¸à¤¾à¤à¤¸ à¤¬à¤‚à¤¦` | `REMOVE_BREATH_REMINDER` | à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¹à¤Ÿà¤¾ à¤¦à¤¿à¤¯à¤¾ |
| ğŸ“ **Take Note** | `à¤¨à¥‹à¤Ÿ à¤²à¤¿à¤–à¥‹ [text]` | `TAKE_NOTE` | à¤¨à¥‹à¤Ÿ à¤²à¤¿à¤– à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆ |
| ğŸ“– **Read Notes** | `à¤¨à¥‹à¤Ÿ à¤ªà¤¢à¤¼à¥‹` | `READ_NOTES` | à¤†à¤ªà¤•à¥‡ à¤¨à¥‹à¤Ÿ: ... |
| â• **Add to List** | `à¤²à¤¿à¤¸à¥à¤Ÿ à¤®à¥‡à¤‚ à¤œà¥‹à¤¡à¤¼à¥‹ [item]` | `ADD_LIST_ITEM` | à¤²à¤¿à¤¸à¥à¤Ÿ à¤®à¥‡à¤‚ à¤œà¥‹à¤¡à¤¼ à¤¦à¤¿à¤¯à¤¾ |
| ğŸ“ƒ **Show List** | `à¤²à¤¿à¤¸à¥à¤Ÿ à¤¦à¤¿à¤–à¤¾à¤“` | `READ_LIST` | à¤†à¤ªà¤•à¥€ à¤²à¤¿à¤¸à¥à¤Ÿ: ... |
| ğŸ”¢ **Calculate** | `à¤œà¥‹à¤¡à¤¼` Â· `à¤˜à¤Ÿà¤¾à¤“` Â· `à¤—à¥à¤£à¤¾` Â· `à¤­à¤¾à¤—` | `CALCULATE` | (arithmetic result) |
| â° **Set Reminder** | `à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤²à¤—à¤¾à¤“ [text]` | `SET_CUSTOM_REMINDER` | à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¸à¥‡à¤µ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆ |
| âŒ **Remove Reminder** | `à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¹à¤Ÿà¤¾à¤“` | `REMOVE_CUSTOM_REMINDER` | à¤¸à¤­à¥€ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤° à¤¹à¤Ÿà¤¾ à¤¦à¤¿à¤ à¤—à¤ |
| ğŸ“‹ **Read Reminders** | `à¤®à¥‡à¤°à¥‡ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤°` | `READ_CUSTOM_REMINDER` | à¤†à¤ªà¤•à¥‡ à¤°à¤¿à¤®à¤¾à¤‡à¤‚à¤¡à¤°: ... |
| ğŸ’Š **Medication Start** | `à¤¦à¤µà¤¾à¤ˆ à¤¶à¥à¤°à¥‚` | `SET_MED_TRACK` | à¤¦à¤µà¤¾à¤ˆ à¤Ÿà¥à¤°à¥ˆà¤•à¤¿à¤‚à¤— à¤¶à¥à¤°à¥‚ |
| ğŸ’Š **Medication Remind** | `à¤¦à¤µà¤¾à¤ˆ à¤¯à¤¾à¤¦` | `TRIGGER_MED_REMINDER` | à¤¦à¤µà¤¾à¤ˆ à¤²à¥‡à¤¨à¥‡ à¤•à¤¾ à¤¸à¤®à¤¯ à¤¹à¥‹ à¤—à¤¯à¤¾ |
| ğŸ›‘ **Medication Stop** | `à¤¦à¤µà¤¾à¤ˆ à¤¬à¤‚à¤¦` | `STOP_MED_TRACK` | à¤¦à¤µà¤¾à¤ˆ à¤Ÿà¥à¤°à¥ˆà¤•à¤¿à¤‚à¤— à¤¬à¤‚à¤¦ |
| ğŸ”„ **Restart** | `à¤°à¥€à¤¸à¥à¤Ÿà¤¾à¤°à¥à¤Ÿ` | `SYSTEM_RESTART` | (restarts assistant process) |
| â¹ï¸ **Shutdown** | `à¤¡à¤¿à¤µà¤¾à¤‡à¤¸ à¤¬à¤‚à¤¦` Â· `à¤¬à¤‚à¤¦ à¤¹à¥‹ à¤œà¤¾à¤“` | `SYSTEM_SHUTDOWN` | (exits cleanly) |

---

## ğŸ§ª Running Tests

Each pipeline stage can be tested independently â€” **no microphone required**:

```cmd
:: ASR â€” inference with dummy silent audio
python tests\test_asr.py

:: NLU â€” intent matching across 4 sample Hindi commands
python tests\test_nlu.py

:: Task Engine â€” intent dispatch and Hindi response
python tests\test_task_engine.py

:: TTS â€” speaks a Hindi test sentence aloud
python tests\test_tts.py
```

---

## ğŸ§¹ Cleanup

Removes `__pycache__` directories, temporary `.wav` files, and `.log` files:

```cmd
python tools\cleanup_project.py
```

---

## âš¡ Performance

| Pipeline Stage | Windows PC (i5 12th Gen) | RPi 4 ARM (Projected) |
|---|---|---|
| VAD per frame | < 1 ms | ~2 ms |
| Audio Processor | < 1 ms | < 2 ms |
| ASR Inference (ONNX) | ~80â€“120 ms | ~280â€“380 ms |
| NLU Rule Engine | < 1 ms | < 1 ms |
| Task Engine | < 5 ms | < 5 ms |
| TTS Piper | ~150â€“250 ms | ~320â€“550 ms |
| **Total End-to-End** | **~300â€“400 ms** | **~700â€“1050 ms** |

Both targets comfortably within the **2-second** requirement.

---

## ğŸ”§ Tech Stack

| Component | Technology |
|---|---|
| Language | Python 3.11 |
| ASR Model | IndicWav2Vec2 Hindi (AI4Bharat) â€” ONNX export |
| ASR Inference | ONNX Runtime 1.14+ â€” CPUExecutionProvider |
| TTS Engine | Piper â€” `hi_IN-pratham-medium.onnx` |
| VAD | Silero VAD â€” PyTorch via `torch.hub` |
| NLU | Rule Engine (25+ intents) + IndicBERT fallback |
| Audio I/O | sounddevice + soundfile |
| Data Storage | JSON (local) â€” reminders, notes, medical records |

---

## ğŸ”’ Privacy & Security

Privacy is a **first-class architectural requirement** in this project:

- **Zero network egress** â€” no API calls, DNS lookups, or socket connections at runtime
- **No audio logging** â€” microphone audio lives in RAM only; temp WAV deleted after every TTS call
- **Local data only** â€” reminders and notes stored as JSON on-device, no cloud sync
- **Wakeword gating** â€” full ASR only runs after `à¤¸à¥à¤¨à¥‹ à¤¸à¤¾à¤¥à¥€` is confirmed
- **Open-source stack** â€” every component (Piper, ONNX Runtime, Silero VAD, IndicWav2Vec2) is fully auditable

---

## ğŸ“¦ Model Downloads

Model files are too large for standard Git. Download and place them manually:

| Model | Place At | Source |
|---|---|---|
| IndicWav2Vec2 Hindi `.onnx` + `.onnx.data` | `onnx_models/asr/` | [AI4Bharat / Hugging Face](https://huggingface.co/ai4bharat) |
| `vocab.json` + config files | `models/asr/indicwav2vec2_hindi/` | Same as above |
| `hi_IN-pratham-medium.onnx` | `models/tts/piper/` | [Piper Voices](https://github.com/rhasspy/piper/blob/master/VOICES.md) |

---

## ğŸš€ Future Scope

| Area | Planned Improvement |
|---|---|
| **ASR â€” Quantisation** | INT8 static quantisation of IndicWav2Vec2 ONNX (~50% latency reduction on ARM) |
| **ASR â€” Fine-tuning** | Domain-specific fine-tune on command vocabulary using HuggingFace Trainer |
| **NLU** | IndicBERT ONNX intent classifier â€” full fallback integration (interface already in place) |
| **Wakeword** | Continuous detection via openWakeWord + custom Hindi wakeword training |
| **TTS** | Streaming Piper output â€” eliminate temp WAV file (~100 ms latency saving) |
| **Hardware** | GPIO LED status indicators on Raspberry Pi (wake / ASR / speaking states) |
| **Storage** | SQLite backend replacing JSON flat files for reminders and medical records |
| **Platform** | Raspberry Pi 5 support (Cortex-A76 â€” projected ~150â€“200 ms ASR latency) |

---

## ğŸ™ Acknowledgements

| Resource | Role |
|---|---|
| [AI4Bharat â€” IndicWav2Vec2](https://ai4bharat.org/indicwav2vec) | Hindi ASR model â€” pre-trained on 40+ hours Hindi audio |
| [Rhasspy Piper](https://github.com/rhasspy/piper) | Offline neural TTS with ARM binary support |
| [Silero VAD](https://github.com/snakers4/silero-vad) | Lightweight real-time voice activity detection |
| [ONNX Runtime](https://onnxruntime.ai) | Cross-platform ML inference engine |
| [espeak-ng](https://github.com/espeak-ng/espeak-ng) | Hindi grapheme-to-phoneme backend for Piper |

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

<div align="center">

**Built with dedication for Hindi Â· Privacy First Â· Offline Always**

</div>
